{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do you want to read from the current position? If so, set restart = False\n",
    "restart = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do you want to load from last checkpoint?\n",
    "checkpoint = 23000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Want chatter?\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set NA values manually\n",
    "na_values = ['#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', '1.#IND', '1.#QNAN', 'N/A', 'NA', 'NULL', 'NaN', 'n/a', 'nan', 'null']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_page_contents (url, verbose=False):\n",
    "    \n",
    "    try_again = True\n",
    "    count = 0\n",
    "    page_contents = None\n",
    "    \n",
    "    while try_again:\n",
    "        \n",
    "        try_again = False\n",
    "\n",
    "        try:\n",
    "            page_contents = urllib2.urlopen(url)\n",
    "        except urllib2.URLError, err:\n",
    "            if hasattr(err, 'code'):\n",
    "                if err.code == 404 and verbose:\n",
    "                    print \"URLError, 404: Likely no wiki page\"\n",
    "            else: \n",
    "                if verbose:\n",
    "                    print \"unknown URLError: Trying again\"\n",
    "                sleep(1)\n",
    "                try_again = True\n",
    "                count = count + 1\n",
    "        except urllib2.HTTPError:\n",
    "            if verbose:\n",
    "                print \"HTTPError: likely no wiki page\"\n",
    "            \n",
    "        if count > 50 and verbose:\n",
    "            print \"Encountered over 50 URLErrors: exiting\"\n",
    "            exit()\n",
    "    \n",
    "    return page_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_links_text (child):\n",
    "    links = child.findAll('a')\n",
    "    nlinks = len(links)\n",
    "\n",
    "    # Getting text from links\n",
    "    linksText = [''] * nlinks\n",
    "    for i in range(0, nlinks):\n",
    "        link = links[i]\n",
    "        if 'href' in link.attrs:\n",
    "            linkText = link['href']\n",
    "            if '/wiki/' in linkText:\n",
    "                linkText = linkText.replace('/wiki/', '')\n",
    "                linksText[i] = linkText\n",
    "\n",
    "    # Filtering text from links\n",
    "    linksText = filter(None, linksText)\n",
    "    linksText = list(set(linksText))\n",
    "    bad_strings = ['/', ':', '!', 'album', 'film', 'at', 'the', 'and']\n",
    "    for z in bad_strings:\n",
    "        linksText = [x for x in linksText if z not in x]\n",
    "    \n",
    "    return linksText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_jazz_musician (name_string, report_string, jms, verbose=False):\n",
    "    \n",
    "    if verbose:\n",
    "        print '--from ' + report_string + \\\n",
    "              ': checking jm status of ' + name_string\n",
    "        \n",
    "    if name_string in jms:\n",
    "        return True\n",
    "    \n",
    "    # Getting page content\n",
    "    wiki_page = \"https://en.wikipedia.org/wiki/\" + name_string\n",
    "    wp_html = get_page_contents(wiki_page, verbose)\n",
    "    if wp_html is None:\n",
    "        return False\n",
    "    wp_soup = BeautifulSoup(wp_html, 'html.parser')\n",
    "    \n",
    "    # Getting tags\n",
    "    th_tags = wp_soup.findAll('th', attrs={'scope':'row'})\n",
    "    \n",
    "    # Checking for occupation\n",
    "    occ_index = -1\n",
    "    count = 0\n",
    "    for tag in th_tags:\n",
    "        if 'Occupation' in tag.text:\n",
    "            occ_index = count\n",
    "            break\n",
    "        count = count + 1\n",
    "    if occ_index == -1:\n",
    "        return False\n",
    "            \n",
    "    # Checking for genre\n",
    "    genre_index = 0\n",
    "    count = 0\n",
    "    for tag in th_tags:\n",
    "        if tag.text == 'Genres':\n",
    "            genre_index = count\n",
    "            break\n",
    "        count = count + 1\n",
    "    if genre_index == -1:\n",
    "        return False\n",
    "    \n",
    "    # Getting genre content and checking for jazz\n",
    "    genre_content = th_tags[genre_index].find_next_sibling()\n",
    "    genre_links = genre_content.findAll('a')\n",
    "    is_jazz = False\n",
    "    jazz_genres = ['jazz', 'Jazz', 'bop']\n",
    "    for link in genre_links:\n",
    "        if any(x in link.text for x in jazz_genres):\n",
    "            is_jazz = True\n",
    "            break\n",
    "    \n",
    "    return is_jazz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mine_double_caps (child, report_string, jms, ignore_italics=False, verbose=False):\n",
    "    jazz_peeps = []\n",
    "    if ignore_italics:\n",
    "        child_print = re.sub('<i.*?/i>', '', str(child), flags=re.DOTALL)\n",
    "    else:\n",
    "        child_print = str(child)\n",
    "    child_words = re.sub(\"[^\\w]\", \" \", child_print).split()\n",
    "    count = 1\n",
    "    while count < len(child_words):\n",
    "        wordi = child_words[count - 1]\n",
    "        wordj = child_words[count]\n",
    "        add_str = ''\n",
    "        is_potential = wordi[0].isupper() and wordj[0].isupper()\n",
    "        if is_potential and len(wordj) == 1 and count < len(child_words) - 1:\n",
    "            additional_word = child_words[count]\n",
    "            add_str = \"_\" + additional_word\n",
    "        if is_potential:\n",
    "            potential_name = wordi + \"_\" + wordj + add_str\n",
    "            if verbose:\n",
    "                print '--potential_name is ' + potential_name\n",
    "            if is_jazz_musician(potential_name, report_string, jms, verbose):\n",
    "                jazz_peeps.append(potential_name)\n",
    "                if len(add_str) == 0:\n",
    "                    count = count + 2\n",
    "                else:\n",
    "                    count = count + 3\n",
    "            else:\n",
    "                count = count + 1\n",
    "        else:\n",
    "            count = count + 1\n",
    "    return jazz_peeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_personnel_if_jazz (name_string, report_string, jms, verbose=False):\n",
    "\n",
    "    if verbose:\n",
    "        print '--from ' + report_string + \\\n",
    "              ': checking album status of ' + name_string    \n",
    "    # Getting page content\n",
    "    wiki_page = \"https://en.wikipedia.org/wiki/\" + name_string\n",
    "    wp_html = get_page_contents(wiki_page, verbose)\n",
    "    if wp_html is None:\n",
    "        return [False, None, jms]\n",
    "    wp_soup = BeautifulSoup(wp_html, 'html.parser')\n",
    "    \n",
    "    # Getting first description tag checking for \"Album\" link\n",
    "    th_tags = wp_soup.find('th', attrs={'class':'description'})\n",
    "    if th_tags is None:\n",
    "        return [False, None, jms]\n",
    "    if th_tags.findChildren('a', attrs={'title':'Album'}) is None:\n",
    "        return [False, None, jms]\n",
    "        \n",
    "    # Checking genre [genre -> parent -> sibling -> genre text]\n",
    "    genre_tag = wp_soup.find('a', attrs={'title':'Music genre'})\n",
    "    if genre_tag is None:\n",
    "        return [False, None, jms]\n",
    "    genre_text = genre_tag.parent.find_next_sibling().text\n",
    "    jazz_genres = ['jazz', 'Jazz', 'bop']\n",
    "    if all(x not in genre_text for x in jazz_genres):\n",
    "        return [False, None, jms]\n",
    "        \n",
    "    # Find personnel header\n",
    "    if wp_soup.findAll('h2') is None:\n",
    "        return [False, None, jms]\n",
    "    personnel_tag = None\n",
    "    for tag in wp_soup.findAll('h2'):\n",
    "        if tag.find('span', attrs={'id':'Personnel'}):\n",
    "            personnel_tag = tag\n",
    "    if personnel_tag is None:\n",
    "        return [False, None, jms]\n",
    "            \n",
    "    # Mining double caps and links from personnel list\n",
    "    person_list = []\n",
    "    next_sibling = personnel_tag\n",
    "    move_on = True\n",
    "    while move_on:\n",
    "        next_sibling = next_sibling.find_next_sibling()\n",
    "        if next_sibling is None or next_sibling.name in ['h2']:\n",
    "            break\n",
    "        else:\n",
    "            # Mining double caps\n",
    "            jazz_peeps = mine_double_caps(next_sibling, report_string, jms, verbose)\n",
    "            jazz_peeps = list(set(jazz_peeps))\n",
    "            person_list = person_list + jazz_peeps\n",
    "            jms.update(jazz_peeps)\n",
    "\n",
    "            # Mining links\n",
    "            linksText = get_links_text(next_sibling)\n",
    "            for link in linksText:\n",
    "                if is_jazz_musician(link, name_string, jms, verbose):\n",
    "                    jms.add(link)\n",
    "                    person_list = person_list + [link]\n",
    "    person_list = list(set(person_list))\n",
    "                \n",
    "    # Getting album release text\n",
    "    released_text = ''\n",
    "    th_rows = wp_soup.findAll('th', attrs={'scope':'row'})\n",
    "    if (len(th_rows) > 0):\n",
    "        #if len(th_rows) == 1:\n",
    "        #    th_rows = [th_rows]\n",
    "        # *** If you feel the need to put these in, try mining Habana_(album) ***\n",
    "        for tag in th_rows:\n",
    "            if tag.text == \"Recorded\" or tag.text== \"Released\":\n",
    "                released_tag = tag\n",
    "                released_text = tag.find_next_sibling().text\n",
    "                released_text = released_text.replace(u'\\xa0', u' ')\n",
    "                released_text = re.sub('\\[.*?\\]', '', released_text, flags=re.DOTALL)\n",
    "    \n",
    "    # Getting data frame to return\n",
    "    dfData = {'Musician2': person_list,\n",
    "              'Album': [name_string] * len(person_list),\n",
    "              'Released': [released_text] * len(person_list)}\n",
    "    returnDf = pd.DataFrame(data=dfData)\n",
    "    \n",
    "    return [True, returnDf, jms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_jazz_musicians_table (table, report_string, jms, jas, verbose=False):\n",
    "    \n",
    "    # Get all row tags\n",
    "    trows = table.find_all('tr')\n",
    "\n",
    "    # Names that signify the album name column\n",
    "    album_col_names = ['Album', 'Album Title', 'Title', 'Album title']\n",
    "\n",
    "    # Initializing edge list\n",
    "    dfcols = ['Musician2', 'Album', 'Released']\n",
    "    album_jazz_musicians = pd.DataFrame(columns=dfcols)\n",
    "\n",
    "    # Parse rows\n",
    "    for i in range(0, len(trows)):\n",
    "\n",
    "        # Find row tags\n",
    "        row_i = trows[i]\n",
    "        row_i_tags = row_i.find_all()\n",
    "\n",
    "        # Populate the cells of the row\n",
    "        row_cells = [row_i_tags[0]]\n",
    "        while not row_cells[-1].find_next_sibling() is None:\n",
    "            row_cells.append(row_cells[-1].find_next_sibling())\n",
    "        ncol = len(row_cells)\n",
    "\n",
    "        if i == 0:\n",
    "            # Finding album column\n",
    "            album_col = None\n",
    "            table_ncol = ncol\n",
    "            for j in range(0, table_ncol):\n",
    "                if any(x == row_cells[j].text for x in album_col_names):\n",
    "                    album_col = j\n",
    "            if album_col is None:\n",
    "                return [album_jazz_musicians, jms, jas]\n",
    "        else:\n",
    "            if ncol < table_ncol:\n",
    "                continue\n",
    "            jm_add = pd.DataFrame(columns=dfcols)\n",
    "            # Check out album title with album col\n",
    "            mine_other_cells = False\n",
    "            album_name_children = row_cells[album_col].findChildren()\n",
    "            link_tag = None\n",
    "            for child in album_name_children:\n",
    "                if child.has_attr('href'):\n",
    "                    if 'wiki' in child['href']:\n",
    "                        link_tag = child\n",
    "            if link_tag is None:\n",
    "                try:\n",
    "                    album_name = str(row_cells[album_col].text)\n",
    "                except UnicodeEncodeError:\n",
    "                    continue\n",
    "                album_name = re.sub('\\[.*?\\]', '', album_name, flags=re.DOTALL)\n",
    "                mine_other_cells = True\n",
    "            else:\n",
    "                href = link_tag['href']\n",
    "                album_name = str(href.encode('ascii', 'replace'))\n",
    "                album_name = re.sub('/wiki/', '', album_name)\n",
    "                if album_name not in jas:\n",
    "                    album_res = get_personnel_if_jazz(album_name, report_string, jms, verbose)\n",
    "                    if album_res[0]:\n",
    "                        jm_add = album_res[1]\n",
    "                        jas.add(album_name)\n",
    "                        jms = album_res[2]\n",
    "                    else:\n",
    "                        mine_other_cells = True\n",
    "                else: \n",
    "                    mine_other_cells = False\n",
    "            # Check out other cells if album name was not a link\n",
    "            if mine_other_cells and len(row_cells) > 1:\n",
    "                jm_add = pd.DataFrame(columns=dfcols)\n",
    "                check_cols = range(0, ncol)\n",
    "                check_cols.remove(album_col)\n",
    "                for j in check_cols:\n",
    "                    jazz_peeps = mine_double_caps(row_cells[j], report_string, jms, verbose)\n",
    "                    jms.update(jazz_peeps)\n",
    "                    njps = len(jazz_peeps)\n",
    "                    if njps > 0:\n",
    "                        addDf = pd.DataFrame({'Musician2':jazz_peeps,\n",
    "                                              'Album':[album_name] * njps,\n",
    "                                              'Released':['0000'] * njps})\n",
    "                        jm_add = jm_add.append(addDf)\n",
    "            album_jazz_musicians = album_jazz_musicians.append(jm_add)\n",
    "    \n",
    "    return [album_jazz_musicians, jms, jas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_jazz_musicians_discography (name_string, report_string, jms, jas, verbose=False):\n",
    "\n",
    "    if verbose:\n",
    "        print '--from ' + report_string + \\\n",
    "              ': scraping separate discography page wiki/' + name_string\n",
    "        \n",
    "    # Initializing edge list\n",
    "    dfcols = ['Musician2', 'Album', 'Released']\n",
    "    album_jazz_musicians = pd.DataFrame(columns=dfcols)\n",
    "\n",
    "    # Getting page content\n",
    "    wiki_page = \"https://en.wikipedia.org/wiki/\" + name_string\n",
    "    wp_html = get_page_contents(wiki_page, verbose)\n",
    "    wp_soup = BeautifulSoup(wp_html, 'html.parser')\n",
    "\n",
    "    # Finding the first legitimate h2 that could have real content\n",
    "    current_tag = None\n",
    "    h2s = wp_soup.findAll('h2')\n",
    "    for tag in h2s:\n",
    "        all_children = tag.findAll()\n",
    "        if len(all_children) > 0:\n",
    "            first_child = all_children[0]\n",
    "            if first_child.has_attr('class'):\n",
    "                if str(first_child['class'][0]) == 'mw-headline':\n",
    "                    current_tag = tag\n",
    "                    break\n",
    "    if current_tag is None:\n",
    "        return [album_jazz_musicians, jms, jas]\n",
    "        \n",
    "    # Cycling through h2 siblings\n",
    "    comp_names = [\"Compilation\", \"compilation\", \"Box\", \"box\"]\n",
    "    do_next_section = True\n",
    "    while not 'References' in current_tag.find_next_sibling().text:\n",
    "        current_tag = current_tag.find_next_sibling()\n",
    "        if do_next_section:\n",
    "            if current_tag.name == 'table':\n",
    "                table_res = get_jazz_musicians_table(current_tag, report_string, jms, jas, verbose)\n",
    "                jms = table_res[1]\n",
    "                jas = table_res[2]\n",
    "                album_jazz_musicians = album_jazz_musicians.append(table_res[0])\n",
    "            elif current_tag.name == 'ul':\n",
    "                link_tags = current_tag.findAll('a')\n",
    "                for link_tag in link_tags:\n",
    "                    href = link_tag['href']\n",
    "                    album_name = str(href.encode('ascii', 'replace'))\n",
    "                    album_name = re.sub('/wiki/', '', album_name)\n",
    "                    if album_name not in jas:\n",
    "                        album_res = get_personnel_if_jazz(album_name, report_string, jms, verbose)\n",
    "                        if album_res[0]:\n",
    "                            album_jazz_musicians = album_jazz_musicians.append(album_res[1])\n",
    "                            jas.add(album_name)\n",
    "                            jms = album_res[2]\n",
    "            else:\n",
    "                if any(x in current_tag.text for x in comp_names):\n",
    "                    do_next_table = False\n",
    "        else:\n",
    "            do_next_section = True\n",
    "        if current_tag.find_next_sibling() is None:\n",
    "            break\n",
    "\n",
    "    return [album_jazz_musicians, jms, jas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_jazz_musicians (name_string, jms, jas, verbose=False):\n",
    "    \n",
    "    if verbose:\n",
    "        print 'getting jazz musicians from ' + name_string\n",
    "\n",
    "    # Getting page content\n",
    "    wiki_page = \"https://en.wikipedia.org/wiki/\" + name_string\n",
    "    wp_html = get_page_contents(wiki_page, verbose)\n",
    "    wp_soup = BeautifulSoup(wp_html, 'html.parser')\n",
    "    \n",
    "    # Getting links\n",
    "    links = wp_soup.findAll('a')\n",
    "    nlinks = len(links)\n",
    "    \n",
    "    # Getting text from links\n",
    "    linksText = [''] * nlinks\n",
    "    for i in range(0, nlinks):\n",
    "        link = links[i]\n",
    "        if 'href' in link.attrs:\n",
    "            linkText = link['href']\n",
    "            if '/wiki/' in linkText:\n",
    "                linkText = linkText.replace('/wiki/', '')\n",
    "                linksText[i] = linkText\n",
    "                \n",
    "    # Filtering text from links\n",
    "    linksText = filter(None, linksText)\n",
    "    linksText = list(set(linksText))\n",
    "    bad_strings = ['/', ':', '!', 'album', 'film', 'at', 'the', 'and']\n",
    "    for z in bad_strings:\n",
    "        linksText = [x for x in linksText if z not in x]\n",
    "        \n",
    "    # Finding jazz musicians\n",
    "    mentioned_jazz_musicians = []\n",
    "    dfcols = ['Musician2', 'Album', 'Released']\n",
    "    album_jazz_musicians = pd.DataFrame(columns=dfcols)\n",
    "    for link in linksText:\n",
    "        if is_jazz_musician(link, name_string, jms, verbose):\n",
    "            mentioned_jazz_musicians.append(link)\n",
    "            jms.add(link)\n",
    "        else:\n",
    "            ar_report_string = name_string + '/' + link\n",
    "            if link not in jas:\n",
    "                album_res = get_personnel_if_jazz(link, ar_report_string, jms)                \n",
    "                if album_res[0]:\n",
    "                    album_jazz_musicians = album_jazz_musicians.append(album_res[1])\n",
    "                    jas.add(link)\n",
    "                    jms = album_res[2]\n",
    "                \n",
    "    # Find discography/recordings header\n",
    "    if wp_soup.findAll('h2') is None:\n",
    "        print \"--no h2 tags, returning\"\n",
    "        album_jazz_musicians['Musician1'] = pd.Series([name_string] * album_jazz_musicians.shape[0])\n",
    "        return [album_jazz_musicians, jms, jas]\n",
    "    discography_tag = None\n",
    "    for tag in wp_soup.findAll('h2'):\n",
    "        span_tags = tag.findAll('span')\n",
    "        for span in span_tags:\n",
    "            if ('discography' in span.text) or ('Discography' in span.text) or ('Recordings' in span.text):\n",
    "                discography_tag = tag\n",
    "    if discography_tag is None:\n",
    "        print \"--discography_tag is None, returning\"\n",
    "        album_jazz_musicians['Musician1'] = pd.Series([name_string] * album_jazz_musicians.shape[0])\n",
    "        return [album_jazz_musicians, jms, jas]\n",
    "\n",
    "    # Finding if there is a separate discography page\n",
    "    disc_link = None\n",
    "    current_tag = discography_tag\n",
    "    while current_tag.find_next_sibling() is not None and not current_tag.find_next_sibling().name == 'h2':\n",
    "        current_tag = current_tag.find_next_sibling()\n",
    "        # Mine the links\n",
    "        tag_links = current_tag.findAll('a')\n",
    "        for link in tag_links:\n",
    "            href = link['href']\n",
    "            link_href = str(href.encode('ascii', 'replace'))\n",
    "            if (('discography' in link_href) or ('Discography' in link_href)) and ('wiki' in link_href):\n",
    "                disc_link = link_href\n",
    "            \n",
    "    if disc_link is None:    \n",
    "        # Finding all unlinked jazz musicians in discography\n",
    "        #disc_mentions = []\n",
    "        #for child in discography_sib.findChildren():\n",
    "        #    jazz_peeps = mine_double_caps(child, name_string, jms, ignore_italics=True)\n",
    "        #    jms.update(jazz_peeps)\n",
    "        #    njps = len(jazz_peeps)\n",
    "        #    if njps > 0:\n",
    "        #        add_data = {'Musician2': jazz_peeps, \n",
    "        #                    'Album': ['Disc_mention'] * njps,\n",
    "        #                    'Released': ['0000'] * njps}\n",
    "        #        album_jazz_musicians.append(pd.DataFrame(add_data))\n",
    "        # Cycling through h2 siblings\n",
    "        current_tag = discography_tag\n",
    "        while current_tag.find_next_sibling() is not None and not current_tag.find_next_sibling().name == 'h2':\n",
    "            current_tag = current_tag.find_next_sibling()\n",
    "            # Mine the links\n",
    "            tag_links = current_tag.findAll('a')\n",
    "            for link in tag_links:\n",
    "                href = link['href']\n",
    "                album_name = str(href.encode('ascii', 'replace'))\n",
    "                album_name = re.sub('/wiki/', '', album_name)\n",
    "                if album_name not in jas:\n",
    "                    album_res = get_personnel_if_jazz(album_name, name_string, jms, verbose)\n",
    "                    if album_res[0]:\n",
    "                        album_jazz_musicians = album_jazz_musicians.append(album_res[1])\n",
    "                        jas.add(album_name)\n",
    "                        jms = album_res[2]\n",
    "    else:\n",
    "        disc_link = re.sub('/wiki/', '', disc_link)\n",
    "        disc_jazz_musicians = get_jazz_musicians_discography(disc_link, name_string, jms, jas, verbose)\n",
    "        album_jazz_musicians = album_jazz_musicians.append(disc_jazz_musicians[0])\n",
    "        jms = disc_jazz_musicians[1]\n",
    "        jas = disc_jazz_musicians[2]\n",
    "        \n",
    "    # Formatting album_jazz_musicians\n",
    "    print \"--formatting album_jazz_musicians\"\n",
    "    not_artist = album_jazz_musicians['Musician2'] != name_string\n",
    "    album_jazz_musicians = album_jazz_musicians[not_artist]\n",
    "    dup_erase = ~album_jazz_musicians.duplicated(subset=['Album', 'Musician2'], keep='first')\n",
    "    album_jazz_musicians = album_jazz_musicians[dup_erase]\n",
    "    album_jazz_musicians = album_jazz_musicians.reset_index().drop('index', 1)\n",
    "    album_jazz_musicians['Musician1'] = pd.Series([name_string] * album_jazz_musicians.shape[0], \n",
    "                                                  index=album_jazz_musicians.index)\n",
    "    album_jazz_musicians = album_jazz_musicians[['Musician1', 'Musician2', 'Album', 'Released']]\n",
    "            \n",
    "    return [album_jazz_musicians, jms, jas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if restart:\n",
    "    jms = set()\n",
    "    jas = set()\n",
    "    dfcols = ['Musician1', 'Musician2', 'Album', 'Released']\n",
    "    edge_list = pd.DataFrame(columns=dfcols)\n",
    "    count = 1\n",
    "    scraped = set()\n",
    "    to_scrape = set()\n",
    "    current_jm = \"Miles_Davis\"\n",
    "    checkpoint_num = 1000\n",
    "else:\n",
    "    if checkpoint > 0:\n",
    "        edge_list = pd.read_csv('edge_list_' + str(checkpoint) + '.csv', encoding='utf-8', na_values=na_values, keep_default_na=False)\n",
    "        if edge_list.shape[1] == 5:\n",
    "            edge_list = edge_list.drop(edge_list.columns[0], axis=1)\n",
    "        with open('jms_' + str(checkpoint) + '.txt', 'r') as f:\n",
    "            jms = eval(f.read())\n",
    "        with open('jas_' + str(checkpoint) + '.txt', 'r') as f:\n",
    "            jas = eval(f.read())\n",
    "        with open('to_scrape_' + str(checkpoint) + '.txt', 'r') as f:\n",
    "            to_scrape = eval(f.read())\n",
    "        with open('scraped_' + str(checkpoint) + '.txt', 'r') as f:\n",
    "            scraped = eval(f.read())\n",
    "        with open('count_' + str(checkpoint) + '.txt', 'r') as f:\n",
    "            count = int(eval(f.read()))\n",
    "        with open('checkpoint_num.txt', 'r') as f:\n",
    "            checkpoint_num = checkpoint + 1000\n",
    "        with open('current_jm_' + str(checkpoint) + '.txt', 'r') as f:\n",
    "            current_jm = str(f.read())\n",
    "    else:\n",
    "        edge_list = pd.read_csv('edge_list.csv', encoding='utf-8', na_values=na_values, keep_default_na=False)\n",
    "        if edge_list.shape[1] == 5:\n",
    "            edge_list = edge_list.drop(edge_list.columns[0], axis=1)\n",
    "        with open('jms.txt', 'r') as f:\n",
    "            jms = eval(f.read())\n",
    "        with open('jas.txt', 'r') as f:\n",
    "            jas = eval(f.read())\n",
    "        with open('to_scrape.txt', 'r') as f:\n",
    "            to_scrape = eval(f.read())\n",
    "        with open('scraped.txt', 'r') as f:\n",
    "            scraped = eval(f.read())\n",
    "        with open('count.txt', 'r') as f:\n",
    "            count = int(eval(f.read()))\n",
    "        with open('checkpoint_num.txt', 'r') as f:\n",
    "            checkpoint_num = int(eval(f.read()))\n",
    "        with open('current_jm.txt', 'r') as f:\n",
    "            current_jm = str(f.read())            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 846: doing Muruga_Booker\n",
      "--3316 jazz musicians\n",
      "--6786 jazz albums\n",
      "--23031 current edges\n",
      "--edge_list.shape[1] is 4\n",
      "--formatting album_jazz_musicians\n",
      "Loop 847: doing Anita_Pointer\n",
      "--3317 jazz musicians\n",
      "--6786 jazz albums\n",
      "--23031 current edges\n",
      "--edge_list.shape[1] is 4\n",
      "--formatting album_jazz_musicians\n",
      "Loop 848: doing Ruth_Pointer\n",
      "--3320 jazz musicians\n",
      "--6786 jazz albums\n",
      "--23031 current edges\n",
      "--edge_list.shape[1] is 4\n",
      "--discography_tag is None, returning\n",
      "Loop 849: doing David_Brown_(American_musician)\n",
      "--3320 jazz musicians\n",
      "--6786 jazz albums\n",
      "--23031 current edges\n",
      "--edge_list.shape[1] is 4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-9979acd09bfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"--\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" current edges\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"--\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"edge_list.shape[1] is \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mperson_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_jazz_musicians\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_jm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-0a2cabf24cea>\u001b[0m in \u001b[0;36mget_jazz_musicians\u001b[0;34m(name_string, jms, jas, verbose)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0malbum_jazz_musicians\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdfcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlinksText\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mis_jazz_musician\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mmentioned_jazz_musicians\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mjms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-695ebbbd5c86>\u001b[0m in \u001b[0;36mis_jazz_musician\u001b[0;34m(name_string, report_string, jms, verbose)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwp_html\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mwp_soup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwp_html\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Getting tags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/johnpalowitch/anaconda2/lib/python2.7/site-packages/bs4/__init__.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mParserRejectedMarkup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/johnpalowitch/anaconda2/lib/python2.7/site-packages/bs4/__init__.pyc\u001b[0m in \u001b[0;36m_feed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0;31m# Close out any unfinished strings and close all the open tags.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/johnpalowitch/anaconda2/lib/python2.7/site-packages/bs4/builder/_htmlparser.pyc\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mHTMLParseError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             warnings.warn(RuntimeWarning(\n",
      "\u001b[0;32m/home/johnpalowitch/anaconda2/lib/python2.7/HTMLParser.pyc\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \"\"\"\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoahead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/johnpalowitch/anaconda2/lib/python2.7/HTMLParser.pyc\u001b[0m in \u001b[0;36mgoahead\u001b[0;34m(self, end)\u001b[0m\n\u001b[1;32m    161\u001b[0m                     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_starttag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"</\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m                     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_endtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<!--\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_comment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/johnpalowitch/anaconda2/lib/python2.7/HTMLParser.pyc\u001b[0m in \u001b[0;36mparse_endtag\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0melem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# script or style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdata_elem\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0melem\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdata_elem\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mgtpos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    \n",
    "    if current_jm == \"Joe_Lovano\":\n",
    "        break\n",
    "    \n",
    "    if False:\n",
    "        \n",
    "        null_counts = [edge_list.isnull()['Musician1'].sum(),\n",
    "                       edge_list.isnull()['Musician2'].sum(),\n",
    "                       edge_list.isnull()['Album'].sum(),\n",
    "                       edge_list.isnull()['Released'].sum()]\n",
    "        print \"------Initial null_counts sum check: \" + str(sum(null_counts))\n",
    "\n",
    "        # Saving values\n",
    "        print \"saving work\"\n",
    "        edge_list.to_csv('edge_list.csv', encoding='utf-8')\n",
    "        with open('jms.txt', 'w') as f:\n",
    "            f.write(str(jms))\n",
    "        with open('jas.txt', 'w') as f:\n",
    "            f.write(str(jas))\n",
    "        with open('scraped.txt', 'w') as f:\n",
    "            f.write(str(scraped))\n",
    "        with open('count.txt', 'w') as f:\n",
    "            f.write(str(count))\n",
    "        with open('checkpoint_num.txt', 'w') as f:\n",
    "            f.write(str(checkpoint_num))   \n",
    "        with open('current_jm.txt', 'w') as f:\n",
    "            f.write(str(current_jm))           \n",
    "        with open('to_scrape.txt', 'w') as f:\n",
    "            f.write(str(to_scrape))\n",
    "\n",
    "\n",
    "        # Saving checkpoint\n",
    "        if edge_list.shape[0] > checkpoint_num:\n",
    "            print \"--saving checkpoint\"\n",
    "            print \"--\" + \"edge_list.shape[1] is \" + str(edge_list.shape[1])\n",
    "            edge_list.to_csv('edge_list_' + str(checkpoint_num) + '.csv', encoding='utf-8')\n",
    "            with open('jms_' + str(checkpoint_num) + '.txt', 'w') as f:\n",
    "                f.write(str(jms))\n",
    "            with open('jas_' + str(checkpoint_num) + '.txt', 'w') as f:\n",
    "                f.write(str(jas))\n",
    "            with open('to_scrape_' + str(checkpoint_num) + '.txt', 'w') as f:\n",
    "                f.write(str(to_scrape))\n",
    "            with open('scraped_' + str(checkpoint_num) + '.txt', 'w') as f:\n",
    "                f.write(str(scraped))\n",
    "            with open('current_jm_' + str(checkpoint_num) + '.txt', 'w') as f:\n",
    "                f.write(str(current_jm))            \n",
    "            with open('count_' + str(checkpoint_num) + '.txt', 'w') as f:\n",
    "                f.write(str(count))\n",
    "            checkpoint_num = checkpoint_num + 1000\n",
    "        \n",
    "    \n",
    "        # Checking saved edgelist\n",
    "        edge_list_saved = pd.read_csv('edge_list.csv', encoding='utf-8', na_values=na_values, keep_default_na=False)\n",
    "        null_counts_saved = [edge_list_saved.isnull()['Musician1'].sum(),\n",
    "                             edge_list_saved.isnull()['Musician2'].sum(),\n",
    "                             edge_list_saved.isnull()['Album'].sum(),\n",
    "                             edge_list_saved.isnull()['Released'].sum()]\n",
    "        if sum(null_counts_saved) > 0:\n",
    "            print(\"----saved null counts non-zero\")\n",
    "            break\n",
    "\n",
    "        # Reporting\n",
    "        null_counts = [edge_list.isnull()['Musician1'].sum(),\n",
    "                       edge_list.isnull()['Musician2'].sum(),\n",
    "                       edge_list.isnull()['Album'].sum(),\n",
    "                       edge_list.isnull()['Released'].sum()]\n",
    "        print \"--Sum of null_counts is \" + str(sum(null_counts))\n",
    "        print \"--Does edge_list have any nulls? \" + str(edge_list.isnull().values.any())\n",
    "    \n",
    "    \n",
    "    # Scraping\n",
    "    print \"Loop \" + str(count) + \": doing \" + current_jm\n",
    "    print \"--\" + str(len(jms)) + \" jazz musicians\"\n",
    "    print \"--\" + str(len(jas)) + \" jazz albums\"\n",
    "    print \"--\" + str(edge_list.shape[0]) + \" current edges\"\n",
    "    print \"--\" + \"edge_list.shape[1] is \" + str(edge_list.shape[1])\n",
    "    person_res = get_jazz_musicians(current_jm, jms, jas, verbose)\n",
    "    \n",
    "    \n",
    "    if False:\n",
    "        \n",
    "        # Doing trial save\n",
    "        edge_list_test_in = edge_list.append(person_res[0])\n",
    "        edge_list_test_in.to_csv('edge_list_test.csv', encoding='utf-8')\n",
    "        edge_list_test_out = pd.read_csv('edge_list_test.csv', encoding='utf-8', na_values=na_values, keep_default_na=False)\n",
    "        null_counts_test = [edge_list_test_out.isnull()['Musician1'].sum(),\n",
    "                            edge_list_test_out.isnull()['Musician2'].sum(),\n",
    "                            edge_list_test_out.isnull()['Album'].sum(),\n",
    "                            edge_list_test_out.isnull()['Released'].sum()]\n",
    "        if sum(null_counts_test) > 0:\n",
    "            print(\"----test null counts non-zero\")\n",
    "            break\n",
    "\n",
    "        # Post-scraping updates\n",
    "        print \"--After scraping:\"\n",
    "        print \"----Does person_res[0] have any nulls? \" + str(person_res[0].isnull().values.any())\n",
    "        if person_res[0].isnull().values.any():\n",
    "            print \"----null_values detected in person_res[0]\"\n",
    "            break\n",
    "        else:\n",
    "            print \"----no null_values in person_res[0]\"\n",
    "            \n",
    "    scraped.add(current_jm)\n",
    "    edge_list = edge_list.append(person_res[0])\n",
    "    #if sum(null_counts) > 0:\n",
    "    #    print \"----null values in edge_list detected\"\n",
    "    #    break\n",
    "    jms = person_res[1]\n",
    "    jas = person_res[2]\n",
    "    \n",
    "    \n",
    "    # Restarting loop for next run\n",
    "    to_scrape = jms.difference(scraped)\n",
    "    try:\n",
    "        current_jm = to_scrape.pop()\n",
    "    except KeyError:\n",
    "        break\n",
    "    count = count + 1        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
